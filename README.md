# Elance_web_crawler_and_scrape


'''
Hello,
Looking for someone to program me Crawler and scraper to sites list.

The Crawler should give the urls of all the web pages that have a recipe.
In the Crawler should be an option for automatic run once a day / week (I have not decided but stay the possibility to change) and if this page has been scanned before do not add it to the scraper.

The Scraper should go into each page and extract the recipe name, the URL of the photo of the recipe, preparation time, a list of ingredients that each ingredient in a separate column, Directions, and the URL of the recipe.

I do not care what language it will be written, of course, it is better to be as automatic run as possible and in the end I will have a single database.
'''
